{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "917af0f0",
   "metadata": {},
   "source": [
    "# Scraping Movies Data Using BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4931d9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2c34960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://subslikescript.com/movie/Titanic-120338\n",
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "# Requesting Website for HTML code\n",
    "website = 'https://subslikescript.com/movie/Titanic-120338'\n",
    "print(website)\n",
    "result = requests.get(website)\n",
    "print(result)\n",
    "content = result.text\n",
    "soup = BeautifulSoup(content, 'lxml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d00667b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(soup.prettify())  # prints the HTML of the website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71aa95fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titanic (1997) - full transcript\n",
      "13 meters. You should see it. Okay, take her up and over the bow rail. Mir 2, we're going over the bow.\n",
      "Stay with us. Okay, quiet. We're rolling. Seeing her coming out of the\n",
      "darkness like a ghost shi\n"
     ]
    }
   ],
   "source": [
    "# Locate the box that contains title and transcript\n",
    "box = soup.find('article', class_='main-article')\n",
    "\n",
    "# Locate title and transcript\n",
    "title = box.find('h1').get_text()\n",
    "transcript = box.find('div', class_='full-script').get_text(strip = True, separator= ' ')\n",
    "print(title)\n",
    "print(transcript[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb8c211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting data in a text file with the \"title\" name\n",
    "\n",
    "with open(f'{title}.txt', 'w', encoding='utf-8') as file:\n",
    "    file.write(transcript)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305512ed",
   "metadata": {},
   "source": [
    "# Extracting the links of multiple movie transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c973c94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://subslikescript.com/movies\n",
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "# Requesting Website for HTML code\n",
    "\n",
    "root = 'https://subslikescript.com'  # This is the homepage of the website\n",
    "website = f'{root}/movies' # Concatenating the homepage with the movies section. \n",
    "result = requests.get(website)\n",
    "content = result.text\n",
    "soup = BeautifulSoup(content, 'lxml')\n",
    "print(website)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7ee062c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['movie/How_to_Talk_to_Girls_at_Parties-3859310', 'movie/I_Am_Not_Him-3228886', 'movie/Drengen_der_gik_baglns-109673', 'movie/A_forza_di_sberle-71090', 'movie/Ms_amaneceres-1846671', 'movie/Friendships_Death-93050', 'movie/Rama_Rao_on_Duty-15028848', 'movie/The_Student-1865357', 'movie/Get_Charlie_Tully-68636', 'movie/Costa_Concordia_-_Chronik_einer_Katastrophe-16025668', 'movie/She_Didnt_Say_No-199014', 'movie/Le_silence_dabord-387593', 'movie/Dead_Scared-366555', 'movie/The_Pentagon_Wars-144550', 'movie/Sheng_zhe_wei_wang-5257730', 'movie/Blackout_Effect-135807', 'movie/The_Invisible_Life-1999246', 'movie/Broad_Peak-8983230', 'movie/The_Second_Civil_War-120086', 'movie/The_Ghost_and_the_Darkness-116409', 'movie/The_Flesh_of_the_Orchid-71297', 'movie/The_Tuskegee_Airmen-114745', 'movie/Demons_Never_Die-1777612', 'movie/The_Catholic_School-10345782', 'movie/Last_Call-1472583', 'movie/Code_Name_Wolverine-115138', 'movie/Dead_Silence-118942', 'movie/My_11th_Mother-1233503', 'movie/Flypaper-132165', 'movie/Robinson_no_niwa-95999']\n"
     ]
    }
   ],
   "source": [
    "# Locate the box that contains a list of movies\n",
    "box = soup.find('article', class_='main-article')\n",
    "\n",
    "\n",
    "# Store each link in \"links\" list (href doesn't consider root aka \"homepage\", so we have to concatenate it later)\n",
    "links = []\n",
    "for link in box.find_all('a', href=True):  # find_all returns a list\n",
    "    links.append(link['href'])\n",
    "\n",
    "print(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e49b2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the movie transcript\n",
    "# Loop through the \"links\" list and sending a request to each link\n",
    "for link in links:\n",
    "    result = requests.get(f'{root}/{link}')\n",
    "    content = result.text\n",
    "    soup = BeautifulSoup(content, 'lxml')\n",
    "    \n",
    "    # Locate the box that contains title and transcript\n",
    "    box = soup.find('article', class_='main-article')\n",
    "    \n",
    "    # Locate title and transcript\n",
    "    title = box.find('h1').get_text()\n",
    "    transcript = box.find('div', class_='full-script').get_text(strip=True, separator=' ')\n",
    "    \n",
    "    # Exporting data in a text file with the \"title\" name\n",
    "#    with open(f'{title}.txt', 'w', encoding='utf-8') as file:\n",
    "#         file.write(transcript)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b371007",
   "metadata": {},
   "source": [
    "# Extracting links from pagination bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0ae247d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requesting Website for HTML code\n",
    "\n",
    "root = 'https://subslikescript.com'  # this is the homepage of the website\n",
    "website = f'{root}/movies_letter-X'  # concatenating the homepage with the movies \"letter-X\" section. You can choose any section (e.g., letter-A, letter-B, ...)\n",
    "result = requests.get(website)\n",
    "content = result.text\n",
    "soup = BeautifulSoup(content, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78e1c0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate the box that contains the pagination bar\n",
    "pagination = soup.find('ul', class_='pagination')\n",
    "pages = pagination.find_all('li', class_='page-item')\n",
    "last_page = pages[-2].text  # this is the number of pages that the website has inside the movies \"letter X\" section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c799f25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Link not working -------\n",
      "movie/X-13560574\n",
      "------ Link not working -------\n",
      "movie/X-118200\n",
      "------ Link not working -------\n",
      "movie/X_-_The_eXploited-6190456\n",
      "------ Link not working -------\n",
      "movie/X-Men_2-290334\n",
      "------ Link not working -------\n",
      "movie/X-Men_Apocalypse-3385516\n",
      "------ Link not working -------\n",
      "movie/X-Men_Days_of_Future_Past-1877832\n",
      "------ Link not working -------\n",
      "movie/X-Men_The_Last_Stand-376994\n",
      "------ Link not working -------\n",
      "movie/X-Rated_2_The_Greatest_Adult_Stars_of_All_Time-6189052\n",
      "------ Link not working -------\n",
      "movie/X_The_Man_with_the_X-Ray_Eyes-57693\n",
      "------ Link not working -------\n",
      "movie/XY-2790182\n",
      "------ Link not working -------\n",
      "movie/Xanadu-81777\n",
      "------ Link not working -------\n",
      "movie/Xenophobia-8571404\n",
      "------ Link not working -------\n",
      "movie/XTC_This_Is_Pop-7465694\n"
     ]
    }
   ],
   "source": [
    "# Extracting the links of multiple movie transcripts inside each page listed\n",
    "\n",
    "# Loop through all tbe pages and sending a request to each link\n",
    "\n",
    "for page in range(1, int(last_page)+1):\n",
    "    result = requests.get(f'{website}?page={page}')  # structure --> https://subslikescript.com/movies_letter-X?page=2\n",
    "    content = result.text\n",
    "    soup = BeautifulSoup(content, 'lxml')\n",
    "\n",
    "    # Locate the box that contains a list of movies\n",
    "    box = soup.find('article', class_='main-article')\n",
    "\n",
    "    # Store each link in \"links\" list (href doesn't consider root aka \"homepage\", so we have to concatenate it later)\n",
    "    links = []\n",
    "    for link in box.find_all('a', href=True):  # find_all returns a list\n",
    "        links.append(link['href'])\n",
    "\n",
    "    #################################################\n",
    "    # Extracting the movie transcript\n",
    "    #################################################\n",
    "\n",
    "    for link in links:\n",
    "        try:  # \"try the code below. if something goes wrong, go to the \"except\" block\"\n",
    "            result = requests.get(f'{root}/{link}')  # structure --> https://subslikescript.com/movie/X-Men_2-290334\n",
    "            content = result.text\n",
    "            soup = BeautifulSoup(content, 'lxml')\n",
    "\n",
    "            # Locate the box that contains title and transcript\n",
    "            box = soup.find('article', class_='main-article')\n",
    "            # Locate title and transcript\n",
    "            title = box.find('h1').get_text()\n",
    "            transcript = box.find('div', class_='full-script').get_text(strip=True, separator=' ')\n",
    "\n",
    "            # Exporting data in a text file with the \"title\" name\n",
    "            with open(f'{title}.txt', 'w') as file:\n",
    "                file.write(transcript)\n",
    "        except:\n",
    "            print('------ Link not working -------')\n",
    "            print(link)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768f903f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
